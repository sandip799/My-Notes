Tags - #huffmanCoding #greedyapproch #daa
# Huffman Coding
- Basically this is used to reduce the size of the data or message
- Suppose you sending a message through a network so it will take cost but if we are able to reduce its size then the sending cost will be less, this is the advantage of this huffman coding
- it is of two types , one is fixed size code and another one is variable size code
- lets understand all the concept using an example
#### Example
##### Fixed Size Code
- Suppose you are sending a message of 20 characters and here only 5 characters are used repeatedly to make 20 character message
- suppose the message looks like 	**ABCDEABCDEABCDEABCDE**
- So if we send this message then as these are characters, all the machine or computers used the **ASCII** codes for characters, so it will take 160 bits because each characters is of 8 bits
- but if you look carefully then this uses only 5 characters repeatedly so if we don't have to use 8 bits for each character and if we use our own method then we can reduce the message size

| A   | B   | C   | D   | E   |
| --- | --- | --- | --- | --- |
| 4   | 4   | 4   | 4   | 4   | 
 - So as this is table where each characters used in the message are written with its frequency
 - and we need only 3 bits to give all the character a new name
- lets give code to each character
	1.  A = 000
	2. B = 001
	3. C = 010
	4. D = 011
	5. E = 100 	
	**TOTAL** = 3 * 20 = 60 bits
- again there is an question arises that `how can the receiver read this code?` ans is we have to give a chart or table so that by looking this the receiver can decrypt the code
- so as there are 5 character we have to write ascii codes for each characters along with the 3 bit code, it looks like
000 == 00000000
001  == 01000100 and so on
- so for this table again extra bits are needed, so total bits needed for this table = **(8 + 3) * 5 = 55**
- then total bits = 60 + 55 = 115bits
##### Variable Size Code
- It follows optimal merge pattern to compress
- `why it named as variable size code?`in previous fixed size example it uses 3 bits for each code but in this this is variable, some character may take 3 bits while some are 1.
- `how it uses the optimal merge pattern?`so first of all it counts different types of characters with its frequency
- lets take an message of 20 characters which is **BCCABBDDAECCBBAEDDCC**

| A   | B   | C   | D   | E   |
| --- | --- | --- | --- | --- |
| 3   | 5   | 6   | 4   | 2   |
- Then order all these in increasing order as we do in optimal merge

| E   | A   | D   | B   | C   |
| --- | --- | --- | --- | --- |
| 2   | 3   | 4   | 5   | 6   |  

- Then draw the tree like we draw in the optimal merge solution
![[huffman coding 1.png]]
- again denote right side of the tree to 0 and left side of the tree to 0, then the tree looks like
![[huffman coding 2 1.png]]
- then traverse from node to give every single character a unique code

| Char | Count | Code |
| ---- | ----- | ---- |
| A    | 3     | 001  |
| B    | 5     | 10   |
| C    | 6     | 11   |
| D    | 4     | 01   |
| E    | 2     | 000  | 
 - If you look carefully then you see that here code size for different variables are differ from each other thats why this is of variable type code
 - here total code size = (3 * 3) + (5 * 2) + (6 * 2) + (4 * 2) + (2 * 3) = 45bits
 - again for decoding in receiver side we need a table, so for that table it takes size = 5 * 8 + 12 = 52bits
 - Then total bits becomes 45+52 = 97bits
 ### Summary
 - So Huffman Coding used for compressing the size of the data or message and as it uses the optimal merge pattern so this included in greedy approach